{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# for convolution functions\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WATCH: Six Minutes Of Conservative Media’s Se...</td>\n",
       "      <td>It s no secret that conservatives and Republic...</td>\n",
       "      <td>News</td>\n",
       "      <td>August 2, 2016</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sanders: Firms must take 'haircut' in Puerto R...</td>\n",
       "      <td>WASHINGTON (Reuters) - Wall Street investment ...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>April 1, 2016</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Factbox: Trump fills top jobs for his administ...</td>\n",
       "      <td>(Reuters) - U.S. President-elect Donald Trump ...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>November 29, 2016</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CNBC EDITOR: Media Must Remember Readers Are N...</td>\n",
       "      <td>A CNBC editor said members of the press need t...</td>\n",
       "      <td>left-news</td>\n",
       "      <td>Jun 29, 2017</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NYC: Turkish Thugs Beat Up Protesters…Deny Fre...</td>\n",
       "      <td>Remember when these Turkish thugs beat up (see...</td>\n",
       "      <td>politics</td>\n",
       "      <td>Sep 22, 2017</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   WATCH: Six Minutes Of Conservative Media’s Se...   \n",
       "1  Sanders: Firms must take 'haircut' in Puerto R...   \n",
       "2  Factbox: Trump fills top jobs for his administ...   \n",
       "3  CNBC EDITOR: Media Must Remember Readers Are N...   \n",
       "4  NYC: Turkish Thugs Beat Up Protesters…Deny Fre...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0  It s no secret that conservatives and Republic...          News   \n",
       "1  WASHINGTON (Reuters) - Wall Street investment ...  politicsNews   \n",
       "2  (Reuters) - U.S. President-elect Donald Trump ...  politicsNews   \n",
       "3  A CNBC editor said members of the press need t...     left-news   \n",
       "4  Remember when these Turkish thugs beat up (see...      politics   \n",
       "\n",
       "                 date label  \n",
       "0      August 2, 2016  fake  \n",
       "1      April 1, 2016   real  \n",
       "2  November 29, 2016   real  \n",
       "3        Jun 29, 2017  fake  \n",
       "4        Sep 22, 2017  fake  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df = pd.read_csv('data/fake-and-real-news-dataset/combined.csv')\n",
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "      <th>fake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WATCH: Six Minutes Of Conservative Media’s Se...</td>\n",
       "      <td>WATCH: Six Minutes Of Conservative Media’s Se...</td>\n",
       "      <td>News</td>\n",
       "      <td>August 2, 2016</td>\n",
       "      <td>fake</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sanders: Firms must take 'haircut' in Puerto R...</td>\n",
       "      <td>Sanders: Firms must take 'haircut' in Puerto R...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>April 1, 2016</td>\n",
       "      <td>real</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Factbox: Trump fills top jobs for his administ...</td>\n",
       "      <td>Factbox: Trump fills top jobs for his administ...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>November 29, 2016</td>\n",
       "      <td>real</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CNBC EDITOR: Media Must Remember Readers Are N...</td>\n",
       "      <td>CNBC EDITOR: Media Must Remember Readers Are N...</td>\n",
       "      <td>left-news</td>\n",
       "      <td>Jun 29, 2017</td>\n",
       "      <td>fake</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NYC: Turkish Thugs Beat Up Protesters…Deny Fre...</td>\n",
       "      <td>NYC: Turkish Thugs Beat Up Protesters…Deny Fre...</td>\n",
       "      <td>politics</td>\n",
       "      <td>Sep 22, 2017</td>\n",
       "      <td>fake</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   WATCH: Six Minutes Of Conservative Media’s Se...   \n",
       "1  Sanders: Firms must take 'haircut' in Puerto R...   \n",
       "2  Factbox: Trump fills top jobs for his administ...   \n",
       "3  CNBC EDITOR: Media Must Remember Readers Are N...   \n",
       "4  NYC: Turkish Thugs Beat Up Protesters…Deny Fre...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0   WATCH: Six Minutes Of Conservative Media’s Se...          News   \n",
       "1  Sanders: Firms must take 'haircut' in Puerto R...  politicsNews   \n",
       "2  Factbox: Trump fills top jobs for his administ...  politicsNews   \n",
       "3  CNBC EDITOR: Media Must Remember Readers Are N...     left-news   \n",
       "4  NYC: Turkish Thugs Beat Up Protesters…Deny Fre...      politics   \n",
       "\n",
       "                 date label   fake  \n",
       "0      August 2, 2016  fake  False  \n",
       "1      April 1, 2016   real   True  \n",
       "2  November 29, 2016   real   True  \n",
       "3        Jun 29, 2017  fake  False  \n",
       "4        Sep 22, 2017  fake  False  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df[\"text\"] = news_df[\"title\"] + \": \" + news_df[\"text\"] \n",
    "news_df[\"fake\"] = news_df[\"label\"].apply(lambda x: True if x == 'real' else False)\n",
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTSequenceClassifier():\n",
    "    \n",
    "    def __init__(self, pretrained_name = \"bert-base-uncased\"):\n",
    "        self.device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "        self.criterion = None\n",
    "        self.optimizer = None\n",
    "        \n",
    "        # https://huggingface.co/transformers/model_doc/bert.html#berttokenizer\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(pretrained_name)\n",
    "        \n",
    "        # https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification\n",
    "        self.model = BertForSequenceClassification.from_pretrained(pretrained_name)\n",
    "        self.model.config.num_labels = 1\n",
    "        \n",
    "        # Freeze the pre trained parameters\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "    def defineLossAndOptimizer(self):\n",
    "        self.criterion = nn.MSELoss().to(self.device)\n",
    "        self.optimizer = optim.SGD(self.model.parameters(), lr=0.01, momentum=0.9)\n",
    "        \n",
    "    def addLayers(self, layers):\n",
    "        modules = []\n",
    "        \n",
    "        for layer in layers:\n",
    "            modules.append(layer)\n",
    "        \n",
    "        self.model.classifier = nn.Sequential(*modules)\n",
    "        self.model = self.model.to(self.device)\n",
    "        \n",
    "    def preprocess_text_samples(self, samples, max_seq_length = 300):\n",
    "    \n",
    "        '''\n",
    "        Adapted from https://www.kaggle.com/clmentbisaillon/classifying-fake-news-with-bert/notebook\n",
    "        '''\n",
    "\n",
    "        encoded_samples = []\n",
    "        \n",
    "        for idx, sample in tqdm(samples.iterrows(), total = samples.shape[0]):\n",
    "            encoded_text = []\n",
    "            words = sample.text.strip().split(' ')\n",
    "            nb_seqs = int(len(words)/max_seq_length)\n",
    "\n",
    "            for i in range(nb_seqs+1):\n",
    "                words_part = ' '.join(words[i*max_seq_length : (i+1)*max_seq_length])\n",
    "\n",
    "                try:\n",
    "                    # https://huggingface.co/transformers/main_classes/tokenizer.html#pretrainedtokenizer\n",
    "                    # encoding using BERT pretrained tokeinizer and converts to pytorch tensors\n",
    "                    encoded_text.append(self.tokenizer.encode(words_part, return_tensors=\"pt\", \n",
    "                                                         max_length = 500, device = self.device))\n",
    "                except:\n",
    "                    print(\"Issue at: \" +str(idx))\n",
    "                    raise\n",
    "\n",
    "            encoded_samples.append(encoded_text)\n",
    "\n",
    "        return encoded_samples\n",
    "    \n",
    "    def train_model():\n",
    "        pass\n",
    "    \n",
    "    def test_model():\n",
    "        pass\n",
    "    \n",
    "    def predict():\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert = BERTSequenceClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [nn.Linear(768, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 2),\n",
    "    nn.Softmax(dim=1)]\n",
    "\n",
    "bert.addLayers(layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Still in progress / testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 91.57it/s]\n"
     ]
    }
   ],
   "source": [
    "nb_samples = 100\n",
    "\n",
    "tensor_list = bert.preprocess_text_samples(news_df[:nb_samples])\n",
    "tensor_labels = news_df.fake[:nb_samples].apply(lambda x: torch.tensor([x]).long().to(device)).to_list()\n",
    "#tensor_labels = news_df.fake[:nb_samples].apply(lambda x: torch.tensor([1.0, 0.0]).float().to(device) if x == 0 else torch.tensor([0.0, 1.0]).float().to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(tensor_list, 'data/tensor.pt')\n",
    "torch.save(tensor_labels, 'data/tensor_labels.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensor_list = torch.load('data/tensor.pt')\n",
    "#tensor_labels = torch.load('data/tensor_labels.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(tensor_list, tensor_labels, test_size=0.4, \n",
    "                                                    random_state=1)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.4, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 1/1 [01:46<00:00, 106.29s/it]\u001b[A\u001b[A\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-194-ba4660167e98>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;31m# save weights after training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"model_after_train.pt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "nb_epochs = 1\n",
    "loss_history = []\n",
    "log_freq = 100\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "criterion = nn.MSELoss().to(device)\n",
    "optimizer = optim.SGD(bert.model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "bert.model.train()\n",
    "\n",
    "for epoch in tqdm(range(nb_epochs)):\n",
    "    \n",
    "    total_loss = 0\n",
    "    \n",
    "    # iterate through the datapoints\n",
    "    for idx, text_tensor in enumerate(X_train):\n",
    "        # set gradients of all optimizers to zero -> avoid accumulation\n",
    "        bert.model.zero_grad()\n",
    "        \n",
    "        # define a tensor for the output \n",
    "        output = torch.zeros((1, 2)).float().to(device)\n",
    "        \n",
    "        # iterate through each part of the text (each part is represented by a tensor)\n",
    "        # and obtain the average of the outputs\n",
    "        for i in range(len(text_tensor)):\n",
    "            input = text_tensor[i]\n",
    "            output += bert.model(input, labels = y_train[idx])[1].float().to(device)/len(text_tensor)\n",
    "        \n",
    "        label = torch.tensor([1.0, 0.0]).float().to(device) if y_train[idx] == 0 else torch.tensor([0.0, 1.0]).float().to(device)\n",
    "        loss = criterion(output[0], label)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # backpropagate\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(\"Epoch ({}/{}): loss = {}\".format(epoch, nb_epochs, total_loss))\n",
    "    #print(\"\\t Training accuracy: \", )\n",
    "    #print(\"\\t Validation accuracy: \", )\n",
    "    #loss_history.append(total_loss)    \n",
    "            \n",
    "# save weights after training\n",
    "torch.save(bert.state_dict(), \"model_after_train.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save weights after training\n",
    "torch.save(bert.model.state_dict(), \"weights/model_after_train.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
