{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# for convolution functions\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WATCH: Six Minutes Of Conservative Media’s Se...</td>\n",
       "      <td>It s no secret that conservatives and Republic...</td>\n",
       "      <td>News</td>\n",
       "      <td>August 2, 2016</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sanders: Firms must take 'haircut' in Puerto R...</td>\n",
       "      <td>WASHINGTON (Reuters) - Wall Street investment ...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>April 1, 2016</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Factbox: Trump fills top jobs for his administ...</td>\n",
       "      <td>(Reuters) - U.S. President-elect Donald Trump ...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>November 29, 2016</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CNBC EDITOR: Media Must Remember Readers Are N...</td>\n",
       "      <td>A CNBC editor said members of the press need t...</td>\n",
       "      <td>left-news</td>\n",
       "      <td>Jun 29, 2017</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NYC: Turkish Thugs Beat Up Protesters…Deny Fre...</td>\n",
       "      <td>Remember when these Turkish thugs beat up (see...</td>\n",
       "      <td>politics</td>\n",
       "      <td>Sep 22, 2017</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   WATCH: Six Minutes Of Conservative Media’s Se...   \n",
       "1  Sanders: Firms must take 'haircut' in Puerto R...   \n",
       "2  Factbox: Trump fills top jobs for his administ...   \n",
       "3  CNBC EDITOR: Media Must Remember Readers Are N...   \n",
       "4  NYC: Turkish Thugs Beat Up Protesters…Deny Fre...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0  It s no secret that conservatives and Republic...          News   \n",
       "1  WASHINGTON (Reuters) - Wall Street investment ...  politicsNews   \n",
       "2  (Reuters) - U.S. President-elect Donald Trump ...  politicsNews   \n",
       "3  A CNBC editor said members of the press need t...     left-news   \n",
       "4  Remember when these Turkish thugs beat up (see...      politics   \n",
       "\n",
       "                 date label  \n",
       "0      August 2, 2016  fake  \n",
       "1      April 1, 2016   real  \n",
       "2  November 29, 2016   real  \n",
       "3        Jun 29, 2017  fake  \n",
       "4        Sep 22, 2017  fake  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df = pd.read_csv('data/fake-and-real-news-dataset/combined.csv')\n",
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "      <th>full_text</th>\n",
       "      <th>fake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WATCH: Six Minutes Of Conservative Media’s Se...</td>\n",
       "      <td>It s no secret that conservatives and Republic...</td>\n",
       "      <td>News</td>\n",
       "      <td>August 2, 2016</td>\n",
       "      <td>fake</td>\n",
       "      <td>WATCH: Six Minutes Of Conservative Media’s Se...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sanders: Firms must take 'haircut' in Puerto R...</td>\n",
       "      <td>WASHINGTON (Reuters) - Wall Street investment ...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>April 1, 2016</td>\n",
       "      <td>real</td>\n",
       "      <td>Sanders: Firms must take 'haircut' in Puerto R...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Factbox: Trump fills top jobs for his administ...</td>\n",
       "      <td>(Reuters) - U.S. President-elect Donald Trump ...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>November 29, 2016</td>\n",
       "      <td>real</td>\n",
       "      <td>Factbox: Trump fills top jobs for his administ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CNBC EDITOR: Media Must Remember Readers Are N...</td>\n",
       "      <td>A CNBC editor said members of the press need t...</td>\n",
       "      <td>left-news</td>\n",
       "      <td>Jun 29, 2017</td>\n",
       "      <td>fake</td>\n",
       "      <td>CNBC EDITOR: Media Must Remember Readers Are N...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NYC: Turkish Thugs Beat Up Protesters…Deny Fre...</td>\n",
       "      <td>Remember when these Turkish thugs beat up (see...</td>\n",
       "      <td>politics</td>\n",
       "      <td>Sep 22, 2017</td>\n",
       "      <td>fake</td>\n",
       "      <td>NYC: Turkish Thugs Beat Up Protesters…Deny Fre...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   WATCH: Six Minutes Of Conservative Media’s Se...   \n",
       "1  Sanders: Firms must take 'haircut' in Puerto R...   \n",
       "2  Factbox: Trump fills top jobs for his administ...   \n",
       "3  CNBC EDITOR: Media Must Remember Readers Are N...   \n",
       "4  NYC: Turkish Thugs Beat Up Protesters…Deny Fre...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0  It s no secret that conservatives and Republic...          News   \n",
       "1  WASHINGTON (Reuters) - Wall Street investment ...  politicsNews   \n",
       "2  (Reuters) - U.S. President-elect Donald Trump ...  politicsNews   \n",
       "3  A CNBC editor said members of the press need t...     left-news   \n",
       "4  Remember when these Turkish thugs beat up (see...      politics   \n",
       "\n",
       "                 date label  \\\n",
       "0      August 2, 2016  fake   \n",
       "1      April 1, 2016   real   \n",
       "2  November 29, 2016   real   \n",
       "3        Jun 29, 2017  fake   \n",
       "4        Sep 22, 2017  fake   \n",
       "\n",
       "                                           full_text   fake  \n",
       "0   WATCH: Six Minutes Of Conservative Media’s Se...  False  \n",
       "1  Sanders: Firms must take 'haircut' in Puerto R...   True  \n",
       "2  Factbox: Trump fills top jobs for his administ...   True  \n",
       "3  CNBC EDITOR: Media Must Remember Readers Are N...  False  \n",
       "4  NYC: Turkish Thugs Beat Up Protesters…Deny Fre...  False  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df[\"text\"] = news_df[\"title\"] + \": \" + news_df[\"text\"] \n",
    "news_df[\"fake\"] = news_df[\"label\"].apply(lambda x: True if x == 'real' else False)\n",
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTSequenceClassifier():\n",
    "    \n",
    "    def __init__(self, pretrained_name = \"bert-base-uncased\"):\n",
    "        self.device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "        self.criterion = None\n",
    "        self.optimizer = None\n",
    "        \n",
    "        # https://huggingface.co/transformers/model_doc/bert.html#berttokenizer\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(pretrained_name)\n",
    "        \n",
    "        # https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification\n",
    "        self.model = BertForSequenceClassification.from_pretrained(pretrained_name)\n",
    "        self.model.config.num_labels = 1\n",
    "        \n",
    "        # Freeze the pre trained parameters\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "    def defineLossAndOptimizer(self):\n",
    "        self.criterion = nn.MSELoss().to(self.device)\n",
    "        self.optimizer = optim.SGD(self.model.parameters(), lr=0.01)\n",
    "        \n",
    "    def addLayers(self, layers):\n",
    "        modules = []\n",
    "        \n",
    "        for layer in layers:\n",
    "            modules.append(layer)\n",
    "        \n",
    "        self.model.classifier = nn.Sequential(*modules)\n",
    "        self.model = self.model.to(self.device)\n",
    "        \n",
    "    def preprocess_text_samples(self, samples, max_seq_length = 300):\n",
    "    \n",
    "        '''\n",
    "        Adapted from https://www.kaggle.com/clmentbisaillon/classifying-fake-news-with-bert/notebook\n",
    "        '''\n",
    "\n",
    "        encoded_samples = []\n",
    "        \n",
    "        for idx, sample in tqdm(samples.iterrows(), total = samples.shape[0]):\n",
    "            encoded_text = []\n",
    "            words = sample.text.strip().split(' ')\n",
    "            nb_seqs = int(len(words)/max_seq_length)\n",
    "\n",
    "            for i in range(nb_seqs+1):\n",
    "                words_part = ' '.join(words[i*max_seq_length : (i+1)*max_seq_length])\n",
    "\n",
    "                try:\n",
    "                    # https://huggingface.co/transformers/main_classes/tokenizer.html#pretrainedtokenizer\n",
    "                    # encoding using BERT pretrained tokeinizer and converts to pytorch tensors\n",
    "                    encoded_text.append(self.tokenizer.encode(words_part, return_tensors=\"pt\", \n",
    "                                                         max_length = 500, device = self.device))\n",
    "                except:\n",
    "                    print(\"Issue at: \" +str(idx))\n",
    "                    raise\n",
    "\n",
    "            encoded_samples.append(encoded_text)\n",
    "\n",
    "        return encoded_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert = BERTSequenceClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [nn.Linear(768, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 2),\n",
    "    nn.Softmax(dim=1)]\n",
    "\n",
    "bert.addLayers(layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Still in progress / testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 85.62it/s]\n"
     ]
    }
   ],
   "source": [
    "nb_samples = 100\n",
    "\n",
    "tensor_list = bert.preprocess_text_samples(news_df[:nb_samples])\n",
    "tensor_labels = news_df[:100].fake.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(tensor_list, 'tensor.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(tensor_list, tensor_labels, test_size=0.4, \n",
    "                                                    random_state=1)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.4, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensors = torch.load('tensor.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,  8112,  7327, 21197,  3550,  2032,  1010,  2096, 18520,  7207,\n",
       "          6369,  1996, 27128,  1997,  1996,  2225,  3448,  7672,  5205,  2728,\n",
       "         17845,  2016,  2170,  2014, 10779,  1012,  2076,  2010,  7327,  6483,\n",
       "          1010,  2343, 13857,  8112,  5228,  2010, 17005,  2005,  1996,  1047,\n",
       "         19658,  2882,  5202,  1998,  2101,  1010,  1996,  2149,  5205,  2728,\n",
       "         17845,  1024,  1998,  2004,  1045,  8339,  2006,  1996,  2440, 11740,\n",
       "          1997,  2010,  6227,  2086,  1010,  2009,  3849,  2000,  2033,  2008,\n",
       "          2010,  2166,  6260,  2875,  3425,  1010,  8112,  2056,  1012,  2066,\n",
       "          1996,  4552,  2002,  9332,  1999,  2010,  4979,  1010,  2066,  2256,\n",
       "          3842,  2993,  1010,  2728, 17845,  8679,  2008, 21864, 17340,  5054,\n",
       "         20925,  2137,  3737,  1010,  1998,  2008,  2003,  1037,  3977,  2000,\n",
       "          2689,  1010,  1037,  3977,  2000,  4553,  1010,  1037,  3977,  2000,\n",
       "          4952,  1010,  1037,  3977,  2000,  2022,  2081,  2062,  3819,  1012,\n",
       "           102]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0][1].reshape(-1)[:512].reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-100-06db3b6722d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mloss_history\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnb_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "nb_epochs = 1\n",
    "\n",
    "total_loss = 0\n",
    "loss_history = []\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in tqdm(range(nb_epochs)):\n",
    "    \n",
    "    # iterate through the datapoints\n",
    "    for idx, text_tensor in enumerate(X_train):\n",
    "        # set gradients of all optimizers to zero -> avoid accumulation\n",
    "        model.zero_grad()\n",
    "        \n",
    "        # define a tensor for the output \n",
    "        output = torch.zeros((1, 2)).float().to(device)\n",
    "        \n",
    "        # iterate through each part of the text (each part is represented by a tensor)\n",
    "        # and sum the output\n",
    "        for i in len(text_tensor[idx]):\n",
    "            input = text_tensor[idx].reshape(-1)[:512].reshape(1, -1)\n",
    "            output += model(input, labels = y_train[idx])[1].float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_every = 300\n",
    "\n",
    "total_loss = 0\n",
    "all_losses = []\n",
    "\n",
    "CUDA_LAUNCH_BLOCKING=1\n",
    "\n",
    "model.train()\n",
    "\n",
    "for idx, row in train_data.iterrows():\n",
    "    text_parts = preprocess_text(str(row['text']))\n",
    "    label = torch.tensor([row['is_fake']]).long().to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    overall_output = torch.zeros((1, 2)).float().to(device)\n",
    "    for part in text_parts:\n",
    "        if len(part) > 0:\n",
    "            try:\n",
    "                input = part.reshape(-1)[:512].reshape(1, -1)\n",
    "                # print(input.shape)\n",
    "                overall_output += model(input, labels=label)[1].float().to(device)\n",
    "            except Exception as e:\n",
    "                print(str(e))\n",
    "\n",
    "#     overall_output /= len(text_parts)\n",
    "    overall_output = F.softmax(overall_output[0], dim=-1)\n",
    "\n",
    "    if label == 0:\n",
    "        label = torch.tensor([1.0, 0.0]).float().to(device)\n",
    "    elif label == 1:\n",
    "        label = torch.tensor([0.0, 1.0]).float().to(device)\n",
    "\n",
    "    # print(overall_output, label)\n",
    "\n",
    "    loss = criterion(overall_output, label)\n",
    "    total_loss += loss.item()\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if idx % print_every == 0 and idx > 0:\n",
    "        average_loss = total_loss / print_every\n",
    "        print(\"{}/{}. Average loss: {}\".format(idx, len(train_data), average_loss))\n",
    "        all_losses.append(average_loss)\n",
    "        total_loss = 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
